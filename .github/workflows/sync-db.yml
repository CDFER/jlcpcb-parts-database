# MIT License, originally written by @Bouni, rewritten by @CDFER
name: "Update parts database"

on:
  schedule:  # Run 2 hours and 15 minutes after yaqwsx/jlcparts updates their database every day at 3 AM UTC
    - cron: "15 5 * * *"
  workflow_dispatch:  # Allow manual triggering of the workflow

jobs:
  scrape-jlc:
    runs-on: ubuntu-latest

    permissions:
      # Give the default GITHUB_TOKEN write permission to commit and push changes to the repository
      contents: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ github.head_ref }}

      - name: Install Python and Pip
        run: |
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends \
            python3 python3-pip

      - name: Install Python dependencies
        run: |
          pip install Brotli

      - name: Scrape JLCPCB
        run: |
          python3 scrape-jlcpcb.py  # Run the Python script

      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Automated update of prefered/basic part list"
          branch: ${{ github.head_ref }}

  update-database:
    name: "Update component database"
    runs-on: ubuntu-latest
    needs: scrape-jlc
    environment: github-pages

    steps:
      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends \
            python3 python3-pip wget p7zip-full

      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install Python dependencies
        run: |
          pip install pandas

      - name: Update database
        run: |
          set -x  # Set bash debugging mode

          # Create a directory and change into it
          mkdir -p db_build
          cd db_build

          # Download the main zip file
          wget -q https://yaqwsx.github.io/jlcparts/data/cache.zip

          # Extract volume information from the zip file
          VOLUMES=$(7z l cache.zip | grep "Volume Index = " | grep -Eoh "[0-9]+")

          # Download all volume files
          for seq in $(seq 1 $VOLUMES); do
            CACHE=$(printf '%02d' $seq)
            wget -q https://yaqwsx.github.io/jlcparts/data/cache.z$CACHE || true
          done

          # Extract the zip files using 7zip
          7z x cache.zip

          # Remove zip files (both cache.zip and cache.z01-cache.z99)
          rm -rf cache.z*

          # Change back to the parent directory
          cd ..

          # Run the Python script to generate the database files
          python3 generate-database.py

      - name: Upload pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          name: github-pages
          path: db_build

  deploy:
    name: "Deploy"
    runs-on: ubuntu-20.04
    needs: update-database
    permissions:
      actions: write
      contents: write
      pages: write
      id-token: write
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    if: github.ref == 'refs/heads/main'

    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

      - name: Clean artifact
        uses: geekyeggo/delete-artifact@v4
        with:
          name: github-pages
